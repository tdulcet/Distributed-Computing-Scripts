{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<h4>(1 - Recommend). Create and save new notebook(s) to enable automatic re-mounting of Drive storage. Copy and paste the below code into a <a href=\"http://colab.research.google.com/#create=true\" target=\"_parent\">new notebook</a> in Colab and follow the directions in the <a href=\"../#how-to-use\" target=\"_parent\">How To Use</a> section of the <em>README</em></h4><h4>(2). Open the pre-formed version in Colab (requires manual authorization each time a notebook is opened) <a href=\"https://colab.research.google.com/github/tdulcet/Distributed-Computing-Scripts/blob/master/google-colab/GoogleColabGPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title # **ðŸ“” Colab GPU and CPU Notebook**#{ vertical-output: true, form-width: \"96%\", display-mode: \"form\" }\n",
    "\n",
    "#@markdown #### â†–ï¸ Click the â–¶ï¸ button after deciding on the options below.\n",
    "#@markdown #### ðŸ”Œ Make sure the GPU is enabled under *Runtimeâ†’Change runtime type*\n",
    "#@markdown #### ðŸ’¡ Keep each notebook **open** in the browser to prevent disconnection. ðŸ“Œ [the tab](https://support.mozilla.org/en-US/kb/pinned-tabs-keep-favorite-websites-open) or move them to a dedicated window for easy access.\n",
    "#@markdown #### â„¹ï¸ This notebook uses both our CUDALucas and Prime95 [Bash install scripts](https://github.com/tdulcet/Distributed-Computing-Scripts#organizations) and our [PrimeNet Python script](https://github.com/tdulcet/Distributed-Computing-Scripts#primenet).\n",
    "#@markdown #### ðŸ“œ Please see the [documentation](https://github.com/tdulcet/Distributed-Computing-Scripts/tree/master/google-colab) for more information and to â¤ï¸ support us.\n",
    "#@markdown #### ðŸ¤· Optionally, create a GIMPS/PrimeNet account [here](https://www.mersenne.org/update/) and [join](https://www.mersenne.org/jteam/) the â€œPortland State Universityâ€ team!\n",
    "\n",
    "prime_ID = 'Default' #@param ['Default'] {allow-input: true}\n",
    "computer_name = 'Default' #@param ['Default'] {allow-input: true}\n",
    "GPU_type_of_work = '100 - First time LL tests' #@param ['100 - First time LL tests', '101 - Double-check LL tests', '102 - World record LL tests', '104 - 100 million digit LL tests']\n",
    "CPU_type_of_work = '150 - First time PRP tests' #@param ['0 - Whatever makes the most sense', '1 - Trial factoring to low limits', '2 - Trial factoring', '4 - P-1 factoring', '5 - ECM for first factors of Mersenne numbers', '6 - ECM on Fermat numbers', '8 - ECM on Mersenne cofactors', '100 - First time LL tests', '101 - Double-check LL tests', '102 - World record LL tests', '104 - 100 million digit LL tests', '150 - First time PRP tests', '151 - Double-check PRP tests', '152 - World record PRP tests', '153 - 100 million digit PRP tests', '154 - First time PRP tests that need P-1 factoring', '155 - Double-check tests using PRP with proof', '160 - First time PRP on Mersenne cofactors', '161 - Double-check PRP on Mersenne cofactors']\n",
    "CPU_prp_proof_power = '5' #@param ['5', '6', '7', '8', '9', '10', '11', '12']\n",
    "#@markdown Every lower power halves Drive storage requirements for PRP tests, but doubles the certification cost.\n",
    "CPU_proof_certification_work = True #@param {type:\"boolean\"}\n",
    "computer_number = 'Default (1)' #@param ['Default (1)', '2', '3', '4'] {allow-input: true}\n",
    "output_type = 'GPU (CUDALucas)' #@param ['GPU and CPU', 'GPU (CUDALucas)', 'CPU (Prime95)'] \n",
    "local_time = 'Pacific' #@param ['Pacific', 'Mountain', 'Central', 'Eastern', 'Alaska', 'Hawaii']\n",
    "debug = 'False' #@param ['False', 'GPU (CUDALucas)', 'CPU (Prime95)']\n",
    "\n",
    "#@markdown #### ðŸ› The *debug* option outputs GPU (CUDALucas) or CPU (Prime95/MPrime) progress and status, then exits.\n",
    "\n",
    "gpu_info = !nvidia-smi --query-gpu=gpu_name --format=csv,noheader # Output what GPU is assigned to this Notebook\n",
    "path_dir = \"\" # helps us to not %cd in the optimize_gpu function\n",
    "\n",
    "import os\n",
    "\n",
    "class StopExecution(Exception):\n",
    "  def _render_traceback_(self):\n",
    "      pass\n",
    "\n",
    "def optimize_gpu():\n",
    "  '''If a new GPU is being used, optimize CUDALucas for using this GPU'''\n",
    "  print('\\nOptimizing CUDALucas for this computer and GPU\\n')\n",
    "  !cd cudalucas && chmod 777 CUDALucas\n",
    "  if not os.path.exists(path_dir + 'cudalucas/' + gpu_info + ' fft.txt'):\n",
    "    !cd cudalucas && ./CUDALucas -cufftbench 1024 8192 5\n",
    "  if not os.path.exists(path_dir + 'cudalucas/' + gpu_info + ' threads.txt'):\n",
    "    !cd cudalucas && ./CUDALucas -threadbench 1024 8192 5 0\n",
    "\n",
    "def run():\n",
    "  '''Run CUDALucas and MPrime'''\n",
    "  print('\\nStarting PrimeNet\\n')\n",
    "  !cd cudalucas; nohup python3 primenet.py -d -t 10800 -T $GPU_type_of_work -l \"{'local' + computer_number + '.ini'}\" >> \"{'primenet' + computer_number + '.out'}\" &\n",
    "  !sleep 1\n",
    "  optimize_gpu()\n",
    "  while not os.path.exists('cudalucas/worktodo' + computer_number+ '.txt'):\n",
    "    print(f'Waiting for worktodo{computer_number}.txt access...')\n",
    "    !sleep 1\n",
    "\n",
    "  if output_type == 'GPU and CPU':\n",
    "    print('\\nStarting Prime95\\n')\n",
    "    !cd mprime_gpu && chmod 777 mprime; nohup ./mprime -A$computer_number -d >> \"{'cpu' + computer_number + '.out'}\" &\n",
    "    print('\\nStarting CUDALucas\\n')\n",
    "    !cd cudalucas; nohup ./CUDALucas -i \"{'CUDALucas' + computer_number + '.ini'}\" >> \"{'gpu' + computer_number + '.out'}\" &\n",
    "    !tail -f \"{'mprime_gpu/cpu' + computer_number + '.out'}\" \"{'cudalucas/gpu' + computer_number + '.out'}\"\n",
    "  elif output_type == 'GPU (CUDALucas)':\n",
    "    print('\\nStarting Prime95\\n')\n",
    "    !cd mprime_gpu && chmod 777 mprime; nohup ./mprime -A$computer_number -d >> \"{'cpu' + computer_number + '.out'}\" &\n",
    "    print('\\nStarting CUDALucas\\n')\n",
    "    !cd cudalucas && ./CUDALucas -k -i \"{'CUDALucas' + computer_number + '.ini'}\" | tee -a \"{'gpu' + computer_number + '.out'}\"\n",
    "  elif output_type == 'CPU (Prime95)':\n",
    "    print('\\nStarting CUDALucas\\n')\n",
    "    !cd cudalucas; nohup ./CUDALucas -i \"{'CUDALucas' + computer_number + '.ini'}\" >> \"{'gpu' + computer_number + '.out'}\" &\n",
    "    print('\\nStarting Prime95\\n')\n",
    "    !cd mprime_gpu && chmod 777 mprime && ./mprime -A$computer_number -d | tee -a \"{'cpu' + computer_number + '.out'}\"\n",
    "\n",
    "def install():\n",
    "  '''Download/Install/Configure CUDALucas then Prime95'''\n",
    "  !wget https://github.com/tdulcet/Distributed-Computing-Scripts/archive/master.zip -nv -O master.zip\n",
    "  !unzip -o master.zip\n",
    "  \n",
    "  print(\"Downloading, building and setting up CUDALucas\\n\")\n",
    "  !cp Distributed-Computing-Scripts-master/{cudalucas2.sh,primenet.py,idletime.sh} .\n",
    "  !sed -i '/^GPU=/,/^fi/ s/^/# /' cudalucas2.sh # Do not check for an Nvidia GPU\n",
    "  !sed -i '/^[[:blank:]]*if ! COMPUTE=/,/^[[:blank:]]*fi/!b; /^[[:blank:]]*fi/a echo \"$COMPUTE\"' cudalucas2.sh # Output CUDA compute capability of GPU\n",
    "  !sed -i 's/\\/$COMPUTE/\\/--generate-code arch=compute_37,code=sm_37 --generate-code arch=compute_50,code=sm_50 --generate-code arch=compute_60,code=sm_60 --generate-code arch=compute_70,code=sm_70 --generate-code arch=compute_75,code=sm_75/' cudalucas2.sh\n",
    "  !sed -i '/^\\.\\/CUDALucas / s/^/# /' cudalucas2.sh # Disable optimization step for faster install\n",
    "  !sed -i '/^nohup / s/^/# /' cudalucas2.sh # Do not start PrimeNet\n",
    "  !sed -i '/^python3 / s/^/# /' cudalucas2.sh # Do not start PrimeNet\n",
    "  !sed -i '/^crontab / s/^/# /' cudalucas2.sh # Do not create a cronjob\n",
    "  !bash -- cudalucas2.sh $computer_number $prime_ID $computer_name $GPU_type_of_work\n",
    "  print(\"Registering computer with PrimeNet\\n\")\n",
    "  !cd cudalucas && python3 primenet.py -d -t 0 -W 1 -T $GPU_type_of_work -u $prime_ID -i \"{'worktodo' + computer_number + '.txt'}\" -r \"{'results' + computer_number + '.txt'}\" -l \"{'local' + computer_number + '.ini'}\" --cudalucas \"{'gpu' + computer_number + '.out'}\" -H $computer_name\n",
    "  !cp -u Distributed-Computing-Scripts-master/google-colab/gpu_optimizations/* cudalucas/\n",
    "\n",
    "  print(\"Downloading and setting up Prime95\\n\")\n",
    "  !cp Distributed-Computing-Scripts-master/{mprime2.sh,mprime2.exp} .\n",
    "  !sed -i 's/\"mprime\"/\"mprime_gpu\"/' mprime2.sh # Name the folder specific to the runtime type\n",
    "  !sed -i '/^\\.\\/mprime / s/^/# /' mprime2.sh # Do not start Prime95\n",
    "  !sed -i '/^nohup / s/^/# /' mprime2.sh # Do not start Prime95\n",
    "  !sed -i '/^crontab / s/^/# /' mprime2.sh # Do not create a cronjob\n",
    "  !sed -i '/^expect {/a \\\\t\"Max emergency memory in GB/worker (*):\" { sleep 1; send -- \"3\\\\r\"; exp_continue }\\n\\t\"Get occasional proof certification work (*):\" { sleep 1; send -- \"CPU_PROOF_CERTIFICATION_WORK\\\\r\"; exp_continue }' mprime2.exp\n",
    "  !sed -i 's/CPU_PROOF_CERTIFICATION_WORK/'$CPU_proof_certification_work'/' mprime2.exp\n",
    "  ![[ -d 'mprime_gpu' ]] && cd mprime_gpu && chmod 777 mprime\n",
    "  !bash -- mprime2.sh $computer_number $prime_ID $computer_name $CPU_type_of_work # Run script\n",
    "  file = '\"' + f'mprime_gpu/prim{int(computer_number):04d}.txt' + '\"'\n",
    "  !echo 'FixedHardwareUID=1' > temp.txt\n",
    "  !echo 'ProofPower={CPU_prp_proof_power}' >> temp.txt\n",
    "  !cat $file >> temp.txt\n",
    "  !mv temp.txt $file\n",
    "  !echo 'PreallocateDisk=0' >> '\"' + f'mprime_gpu/loca{int(computer_number):04d}.txt' + '\"'\n",
    "  run()\n",
    "\n",
    "def debug_exit():\n",
    "  '''Output GPU and output of Prime95 or CUDALucas output'''\n",
    "  if debug == 'GPU (CUDALucas)'and os.path.exists('cudalucas/gpu' + computer_number + '.out'):\n",
    "    print(f\"\\nOutput for computer number {computer_number}:\\n\")\n",
    "    print(\"\\nPrimeNet output:\\n\") \n",
    "    !tail -n 100 \"{'cudalucas/primenet' + computer_number + '.out'}\" # view primenet output\n",
    "    print(\"\\nGPU (CUDALucas) output: \")\n",
    "    !tail -n 100 \"{'cudalucas/gpu' + computer_number + '.out'}\" # view CUDALucas progress\n",
    "    !cd cudalucas && python3 primenet.py -l \"{'local' + computer_number + '.ini'}\" -s\n",
    "    print()\n",
    "  elif debug == 'CPU (Prime95)' and os.path.exists('mprime_gpu/cpu' + computer_number + '.out'):\n",
    "    print(\"\\nCPU (Prime95) output:\\n\") \n",
    "    !tail -n 100 \"{'mprime_gpu/cpu' + computer_number + '.out'}\" # view MPrime progress\n",
    "    !cd mprime_gpu && chmod 777 mprime && ./mprime -s -A$computer_number\n",
    "    print()\n",
    "  else:\n",
    "    print(f'No `{debug}` output file found for debug option and computer number `{computer_number}`.\\n')\n",
    "\n",
    "def load_drive():\n",
    "  '''Load & cd into gdrive for persistent data'''\n",
    "  global path_dir\n",
    "  if os.path.exists(\"/content/drive/My Drive\"): # create your own notebook with our code\n",
    "    %cd \"/content/drive/My Drive\"\n",
    "    path_dir = \"/content/drive/My Drive/GIMPS/\"\n",
    "  else: # use our notebook\n",
    "    print('Warning: Google Drive is not mounted')\n",
    "    print('If you were not expecting this, on the far left click the folder icon, the \"Mount Drive\" folder button, select \"CONNECT TO GOOGLE DRIVE\" ')\n",
    "    print('and then re-execute this cell.')\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    %cd \"/content/gdrive/My Drive\"\n",
    "    path_dir = \"/content/gdrive/My Drive/GIMPS/\"\n",
    "  if \"My Drive/GIMPS\" in os.getcwd(): # don't create a subfolder in GIMPS/\n",
    "    return\n",
    "  !mkdir -p GIMPS\n",
    "  %cd \"GIMPS\"\n",
    "\n",
    "def gpu_check():\n",
    "  '''GPU Check'''\n",
    "  global gpu_info\n",
    "  gpu_info = \"\\n\".join(gpu_info)\n",
    "  if gpu_info.find('failed') >= 0:\n",
    "    print('Select the \"Runtime\" â†’ \"Change runtime type\" â†’ \"GPU\" â†’ \"SAVE\" to enable a GPU accelerator, ')\n",
    "    print('and then re-execute this cell.')\n",
    "    raise StopExecution\n",
    "  print(f'\\nGraphics Processor (GPU):\\t{gpu_info}\\n')\n",
    "\n",
    "gpu_check()\n",
    "!wget https://raw.github.com/tdulcet/Linux-System-Information/master/info.sh -qO - | bash -s # Check System Info\n",
    "!python3 -V\n",
    "print()\n",
    "load_drive()\n",
    "\n",
    "# set local time\n",
    "!rm -f /etc/localtime\n",
    "!ln -s {'/usr/share/zoneinfo/US/' + local_time} /etc/localtime\n",
    "\n",
    "# use/cleanup input from user\n",
    "prime_ID = 'psu' if prime_ID.lower() == 'default' else prime_ID\n",
    "computer_name = \"\" if computer_name.lower() == 'default' else computer_name\n",
    "computer_number = \"1\" if computer_number.lower() == 'default (1)' else computer_number.strip()\n",
    "CPU_type_of_work = CPU_type_of_work.split(\"-\")[0].rstrip()\n",
    "CPU_proof_certification_work = \"y\" if CPU_proof_certification_work else \"n\"\n",
    "GPU_type_of_work = GPU_type_of_work.split(\"-\")[0].rstrip()\n",
    "debug = False if debug == 'False' else debug\n",
    "\n",
    "# Add quotes to string args so script can parse spaces/special characters\n",
    "prime_ID = '\"' + prime_ID + '\"'\n",
    "computer_name = '\"' + computer_name + '\"'\n",
    "\n",
    "\n",
    "if debug:\n",
    "  debug_exit()\n",
    "  raise StopExecution\n",
    "\n",
    "elif not computer_number.isdigit() or int(computer_number) < 0:\n",
    "  print(\"ERROR: Computer number must be a number\")\n",
    "  raise StopExecution\n",
    "\n",
    "elif os.path.exists(f'mprime_gpu/work{int(computer_number):04d}.txt') and os.path.exists('cudalucas/local' + computer_number + '.ini'):\n",
    "  !cd mprime_gpu && echo -e \"$(date)\\t$(sed -n 's/^model name[[:space:]]*: *//p' /proc/cpuinfo | uniq)  $(sed -n 's/^model[[:space:]]*: *//p' /proc/cpuinfo | uniq)\" >> cpus.txt\n",
    "  print('\\nPrevious CPU counts')\n",
    "  !cd mprime_gpu; awk -F'\\t' '{ print $2 }' cpus.txt | sort | uniq -c | sort -nr\n",
    "  !cd cudalucas && echo -e \"$(date)\\t$gpu_info\" >> gpus.txt\n",
    "  print('\\nPrevious GPU counts')\n",
    "  !cd cudalucas; awk -F'\\t' '{ print $2 }' gpus.txt | sort | uniq -c | sort -nr\n",
    "  run()\n",
    "\n",
    "else:\n",
    "  install()\n",
    "\n",
    "print(\"Gracefully exiting...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
